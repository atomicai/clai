{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib, os\n",
    "import torch\n",
    "from clai.tooling import tool\n",
    "from clai.tooling import io\n",
    "from clai.processing import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clai.modeling.module.model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "        '8800 СберМегаМаркет. Купить',\n",
    "        '8800 СберМегаМаркет. Статус доставки и заказа',\n",
    "        '8800 СберМегаМаркет. Другие вопросы',\n",
    "        'Соединить с оператором',\n",
    "        '8800 СберМегаМаркет. Не пришел заказ',\n",
    "        '8800 СберМегаМаркет. Разводящий вопрос',\n",
    "        'Да',\n",
    "        'Прочее',\n",
    "        '8800 СберМегаМаркет. Качество, комплектация, состав заказа',\n",
    "        '8800 СберМегаМаркет. Программа лояльности',\n",
    "        '8800 СберМегаМаркет. Отменить заказ',\n",
    "        '8800 СберМегаМаркет. Узнать условия',\n",
    "        '8800 СберМегаМаркет. Обращение',\n",
    "        '8800 СберМегаМаркет. Изменить заказ',\n",
    "        '8800 СберМегаМаркет. Изменить личные данные',\n",
    "        '8800 СберМегаМаркет. Оплата',\n",
    "        '8800 СберМегаМаркет. Изменить доставку',\n",
    "        '8800 СберМегаМаркет. Заказ отменили',\n",
    "        '8800 СберМегаМаркет. Вернуть деньги',\n",
    "        '8800 СберМегаМаркет. Вернуть товар',\n",
    "        'Нет',\n",
    "        '8800 СберМегаМаркет. Получение заказа',\n",
    "        '8800 СберМегаМаркет. Юридические лица',\n",
    "        '8800 СберМегаМаркет. Промокод'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices available: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Devices available: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm = model.LanguageModel.load(\"coi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = io.load_tokenizer(pretrained_model_name_or_path=\"cointegrated/rubert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='cointegrated/rubert-tiny', vocab_size=29564, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path.home() / \"Dataset\" / \"sber\"\n",
    "max_seq_len = 128\n",
    "text_column_name = \"input_text\"\n",
    "label_column_name = \"topic\"\n",
    "metric = \"f1_macro\"\n",
    "train_filename = \"train.csv\"\n",
    "test_filename = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = processor.Processor.load(\n",
    "    \"klass\",\n",
    "    max_seq_len=max_seq_len,\n",
    "    tokenizer=tokenizer, \n",
    "    data_dir=data_dir, \n",
    "    train_filename=train_filename,\n",
    "    test_filename=test_filename,\n",
    "    dev_split=0.0,\n",
    "    label_list=label_list,\n",
    "    text_column_name=text_column_name, \n",
    "    label_column_name=label_column_name,\n",
    "    metric=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clai.flowing import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806905b8706f4b9ca3b7f9a60eeff429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing Dataset /Users/20107004/Dataset/sber/train.csv:   0%|          | 0/19334 [00:00<?, ? Dicts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89db5591101842e3ad626da016e151ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing Dataset /Users/20107004/Dataset/sber/test.csv:   0%|          | 0/4784 [00:00<?, ? Dicts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n",
      "Currently no support in Processor for returning problematic ids\n"
     ]
    }
   ],
   "source": [
    "data_silo = flow.Flow.load(\"haski\", processor=processor, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clai.modeling.module.head import klass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_head = klass.TextClassificationHead(num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84129d39c39bb9b361f7853acb7b6243d3f403a45fcc2af634404eb225bf0957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
